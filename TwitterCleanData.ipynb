{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84141209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ติดตั้ง Pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0b9252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# เรียกไฟล์ Excel โดยไฟล์อยู่ใน Computer\n",
    "df = pd.read_excel('raw_datas.xlsx', sheet_name='rawdata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dc4049",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import lib python\n",
    "#pip install tweepy==3.10.0\n",
    "import tweepy\n",
    "#pip install pandas\n",
    "import pandas as pd\n",
    "#pip install scikit-learn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#pip install numpy\n",
    "import numpy as np\n",
    "#pip install emoji\n",
    "import emoji\n",
    "#pip install pythainlp\n",
    "from pythainlp.tokenize import word_tokenize\n",
    "from pythainlp.corpus import thai_stopwords\n",
    "import re\n",
    "#pip install wordcloud\n",
    "from wordcloud import WordCloud\n",
    "#pip install matplotlib\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26b5dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(text):\n",
    "    text = str(text)\n",
    "    text = re.sub('[^ก-๙]','',text)\n",
    "    stop_word = list(thai_stopwords())\n",
    "    sentence = word_tokenize(text)\n",
    "    result = [word for word in sentence if word not in stop_word and \" \" not in word]\n",
    "    return text\n",
    "cleaning = []\n",
    "for txt in df[\"text\"]:\n",
    "    cleaning.append(cleanText(txt))\n",
    "cleaning[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1befd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cleaning_Data'] = cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829a9094",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b9338e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(text):\n",
    "    text = str(text)\n",
    "    text = re.sub('[^ก-๙]','',text)\n",
    "    stop_word = list(thai_stopwords())\n",
    "    sentence = word_tokenize(text, engine=\"multi_cut\")\n",
    "    # sentence = word_tokenize(text)\n",
    "    result = [word for word in sentence if word not in stop_word and \" \" not in word]\n",
    "    return \",\".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31351bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(d):  \n",
    "    result = d.split(\",\")\n",
    "    result = list(filter(None, result))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca837b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = []\n",
    "for txt in df['Cleaning_Data']:\n",
    "    new_text.append(cleanText(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11edf5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(tokenizer=tokenize)\n",
    "transformed_data = vectorizer.fit_transform(new_text)\n",
    "count_data = zip(vectorizer.get_feature_names(), np.ravel(transformed_data.sum(axis=0)))\n",
    "keyword_df = pd.DataFrame(columns = ['word', 'count'])\n",
    "keyword_df['word'] = vectorizer.get_feature_names()\n",
    "keyword_df['count'] = np.ravel(transformed_data.sum(axis=0))   \n",
    "keyword_df.sort_values(by=['count'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc456be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write file csv\n",
    "keyword_df.sort_values(by=['count'], ascending=False).head(100).to_excel(\"./clean-datas/Count-Word-countword.xlsx\",encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2499499e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1f2a0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['multi_cut'] = new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c4dc00",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c799616",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write file excel\n",
    "df.to_excel(\"./clean-datas/textcut.xlsx\", columns = ['Cleaning_Data','multi_cut'],encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4a443f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('./clean-datas/TwitterCleanData.xlsx', columns = ['Cleaning_Data'],encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd687eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
